{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "H0F0BJdACsRq"
   },
   "source": [
    "## Task 2.4: MLP in PyTorch\n",
    "\n",
    "ITU KSADMAL1KU-NLP - Advanced Machine Learning for NLP in KCS 2024\n",
    "\n",
    "by Stefan Heinrich, Bertram HÃ¸jer, Christian H. Rasmussen, & material by Kevin Murphy.\n",
    "\n",
    "All info and static material: https://learnit.itu.dk/course/view.php?id=3024579\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "This notebook is a prototypical blueprint for Deep Learning frameworks, usually following four steps:\n",
    "- Data loading and preprocessing (often including Exploratory Data Analysis (EDA))\n",
    "- Building a model by using the Tensorflow or PyTorch API\n",
    "- Training a model (including initialising) until termination (often: convergence)\n",
    "- Analysing the model (often including various steps to achieve interpretability of the model)\n",
    "\n",
    "In Advanced Machine Learning course, we will detail these steps but often revisit these basic framework steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "1KQG9HJ7CsRr"
   },
   "outputs": [],
   "source": [
    "# @title #### Import dependencies\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "np.random.seed(0)  # test with different seeds (for re-running everything)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "eqrCdoy_CsRs"
   },
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "dJyUgUMZCsRs"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# transformations\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "# Create a dataloader for Pytorch training\n",
    "# download and load training dataset\n",
    "trainset = torchvision.datasets.MNIST(root='../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# download and load testing dataset\n",
    "testset = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "figure = plt.figure(figsize=(10, 5))\n",
    "cols, rows = 4, 2\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(trainset), size=(1,)).item()\n",
    "    img, label = trainset[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(f\"Class {label}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "wwUZS5uvCsRs"
   },
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "NouiguBVCsRs"
   },
   "outputs": [],
   "source": [
    "#def get_output_shape(layer, img_size):\n",
    "#    return layer(torch.rand(*(img_size))).data.shape\n",
    "\n",
    "class MNIST_model(nn.Module):\n",
    "  def __init__(self, img_size, fc1_out, fc2_out, class_out):\n",
    "      super(MNIST_model, self).__init__()\n",
    "\n",
    "      self.hidden_layer_1 = nn.Linear(in_features=img_size*img_size, out_features=fc1_out)\n",
    "      self.hidden_layer_2 = nn.Linear(in_features=fc1_out, out_features=fc2_out)\n",
    "      self.output_layer = nn.Linear(in_features=fc2_out, out_features=class_out)\n",
    "\n",
    "  def forward(self, img):\n",
    "\n",
    "    # we flatten the 2D image into one long array\n",
    "    # Start_dim = 1 because we pass the batches\n",
    "    img = img.flatten(start_dim=1)\n",
    "\n",
    "    x = self.hidden_layer_1(img)\n",
    "    x = F.relu(x)\n",
    "    x = self.hidden_layer_2(x)\n",
    "    x = F.relu(x)\n",
    "\n",
    "    x = self.output_layer(x)\n",
    "    x = F.softmax(x, dim=1)\n",
    "\n",
    "    return x\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "img_size = trainloader.dataset.data.shape[1]\n",
    "class_out = trainloader.dataset.targets.unique().size()[0]\n",
    "model = MNIST_model(img_size, 128, 128, class_out)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "TntfU5CvCsRs"
   },
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "65xp9TooCsRt"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "epochs = 5\n",
    "\n",
    "# Setup for training\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# Training loop\n",
    "\n",
    "def get_accuracy(logit, target, batch_size):\n",
    "    # compute accuracy\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  # Put the model in training mode\n",
    "  model = model.train()\n",
    "\n",
    "  train_running_loss = 0.0\n",
    "  train_acc = 0.0\n",
    "  for idx, (images, labels) in enumerate(trainloader):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # loss and optimiser definitions!\n",
    "    logits = model(images)\n",
    "    loss = criterion(logits, labels)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # update model params\n",
    "    optimizer.step()\n",
    "\n",
    "    train_running_loss += loss.detach().item()\n",
    "    train_acc += get_accuracy(logits, labels, batch_size)\n",
    "\n",
    "  print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \\\n",
    "          %(epoch, train_running_loss / idx, train_acc/idx))\n",
    "\n",
    "model = model.eval()\n",
    "test_acc = 0.0\n",
    "for i, (images, labels) in enumerate(testloader, 0):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    test_acc += get_accuracy(outputs, labels, 1)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc/i}, in epoch: {epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "ld0yA-jJCsRt"
   },
   "source": [
    "#### Analyse the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "yH-PfkE6CsRt"
   },
   "outputs": [],
   "source": [
    "# @title ##### Prediction and visualisation\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Derive an histogram over the 10 classes\n",
    "# by counting over the predictions on the test data\n",
    "\n",
    "hist = {k: {l:0 for l in range(10)} for k in range(10)}\n",
    "\n",
    "for (images, labels) in testloader:\n",
    "  images = images.to(device)\n",
    "  labels = labels.to(device)\n",
    "  outputs = model(images)\n",
    "  pred = torch.argmax(outputs).item()\n",
    "  hist[labels[0].item()][pred] += 1"
   ],
   "metadata": {
    "id": "pOeKiYzxWUkM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "kvEnBMw6CsRt"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(16)\n",
    "for idx, (key, val) in enumerate(hist.items()):\n",
    "  ax = fig.add_subplot(3, 4, idx+1)\n",
    "  ax.bar(list(val.keys()), val.values(), color='r')\n",
    "  ax.set_title(f\"Prediction for {key}\")\n",
    "  ax.set_xticks(range(0,10))\n",
    "  ax.set_ylim(0, 1200)\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
