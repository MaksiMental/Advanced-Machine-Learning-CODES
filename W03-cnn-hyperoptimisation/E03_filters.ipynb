{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMFjuZZUVS_b",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Optional revision task 3.1: Understanding filters for CNNs\n",
    "\n",
    "ITU KSADMAL1KU-NLP - Advanced Machine Learning for NLP in KCS 2024\n",
    "\n",
    "by Stefan Heinrich, Bertram HÃ¸jer, Christian H. Rasmussen, & material by Kevin Murphy.\n",
    "\n",
    "All info and static material: https://learnit.itu.dk/course/view.php?id=3024579\n",
    "\n",
    "-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Demonstration of some Filters as used in Convolutional Neural Networks\n",
    "\n",
    "*Hint: We use pytorch for these practical examples. Read up about the concepts of tensor data structures and graph computation in the tutorials and the API that we have introduces last week, if needed!*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "iFQWNDPfoj5I"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# @title #### import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "SyS1TlxI_l8I"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Helper method\n",
    "def tensor_to_image(data: torch.Tensor):\n",
    "  img = plt.imshow(data.numpy())\n",
    "  img.set_cmap('gray')\n",
    "  plt.axis('on')\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Pd-Y_uFd_l8L"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convolution & filters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "KHp04T_yoj5K"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i9oPv1Htd2Ex",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def conv2d(X, K):\n",
    "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zaVHw_MNd9X0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "filtered = conv2d(X, K)\n",
    "\n",
    "# plt.imshow(filtered.numpy(), cmap='gray')\n",
    "tensor_to_image(filtered)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nabPSrVDfRkN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "X = torch.ones((6, 8))\n",
    "X[:, 2:6] = 0\n",
    "tensor_to_image(X)\n",
    "print(pd.DataFrame(X.numpy()))\n",
    "print(f\" shape -> {X.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yhGd5b1_fd_T",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "kernel = torch.tensor([[1.0, -1.0], [1.0, -1.0]])\n",
    "tensor_to_image(kernel)\n",
    "print(pd.DataFrame(kernel.numpy()))\n",
    "print(f\" shape -> {kernel.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8IzvmVwqgxHQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "x_filtered = conv2d(X, kernel)\n",
    "tensor_to_image(x_filtered)\n",
    "print(pd.DataFrame(x_filtered.numpy()))\n",
    "print(f\" shape -> {x_filtered.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qjGIS9r3i7BV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!wget \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Bikesgray.jpg/400px-Bikesgray.jpg\" -O ./bike.jpg\n",
    "im = np.array(Image.open('bike.jpg').convert('L'))\n",
    "im_tens = torch.Tensor(im)\n",
    "tensor_to_image(im_tens)\n",
    "print(f\" shape -> {im_tens.shape}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atTthNa_AMq7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Apply our vertical and horizontal kernels and convolve them through the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WuwOMFZmli6e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "horizontal_res = conv2d(im_tens, kernel)\n",
    "vertical_res = conv2d(im_tens, kernel.t())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6iL_ooZDk3cR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print(f\"shape -> {vertical_res.shape}\")\n",
    "tensor_to_image(horizontal_res.abs())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y_0UvE40o4S1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "tensor_to_image(vertical_res.abs())\n",
    "print(f\"shape -> {vertical_res.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k7EyOkH5o7wN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "c = (horizontal_res ** 2 + vertical_res ** 2) ** 0.5\n",
    "tensor_to_image(c)\n",
    "print(f\"shape -> {c.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7PtWEHi2mM-p",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "sobel_hor = torch.Tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "sobel_ver = sobel_hor.t()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xyenjjLimlra",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "sob_engine_h = conv2d(im_tens, sobel_hor)\n",
    "sob_engine_v = conv2d(im_tens, sobel_ver)\n",
    "\n",
    "total_sobel_img = (sob_engine_h ** 2 + sob_engine_v ** 2) ** 0.5\n",
    "tensor_to_image(total_sobel_img)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tnhS76-KlBIL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Sobel operator gradient directions\n",
    "total_sobel_grad = torch.atan2(sob_engine_v, sob_engine_h)\n",
    "tensor_to_image(total_sobel_grad)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WGwz7dSFqEkQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        # Kernel values\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        # Bias\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return conv2d(x, self.weight) + self.bias"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pKBJx21Atsiv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!wget \"https://upload.wikimedia.org/wikipedia/commons/6/61/Black_Circle.jpg\" -O circle.jpg\n",
    "circle_im = torch.Tensor(np.array(Image.open('circle.jpg').convert('L')))\n",
    "tensor_to_image(circle_im)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hGJaG8wvuEm5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "filtered_circle = conv2d(circle_im, kernel)\n",
    "tensor_to_image(filtered_circle.abs())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yeKJ3c4Dbwzv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "filtered_circle_t = conv2d(circle_im, kernel.t())\n",
    "tensor_to_image(filtered_circle_t.abs())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s0SIBiGIidZ8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "tensor_to_image((filtered_circle_t ** 2 + filtered_circle ** 2) ** 0.5)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JgnGU3d3qNri",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "conv_nn = Conv2D((2,2))\n",
    "\n",
    "# Imput image from the previous example\n",
    "X = torch.ones((6, 8))\n",
    "X[:, 2:6] = 0\n",
    "\n",
    "# Predesigned kernel from the previous example\n",
    "Y = conv2d(X, kernel)\n",
    "\n",
    "lr = 3e-2  # Learning rate\n",
    "\n",
    "for i in range(300):\n",
    "    Y_hat = conv_nn(X)\n",
    "    l = (Y_hat - Y)**2\n",
    "    conv_nn.zero_grad()\n",
    "    l.mean().backward()\n",
    "    # Update the kernel\n",
    "    conv_nn.weight.data[:] -= lr * conv_nn.weight.grad\n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(f'batch {i + 1}, loss {l.mean():.3f}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_stUpLbps4bT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "conv_nn.weight"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAHPAPshitPo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fbpzcFD2l_y6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "circle_im = torch.Tensor(np.array(Image.open('circle.jpg').convert('L')))\n",
    "print(f\"shape -> {circle_im.shape}\")\n",
    "tensor_to_image(circle_im)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Xi2c8Aycmueu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "padded_circle_im = F.pad(circle_im, (1,1,1,1), value=1)\n",
    "print(f\"shape -> {padded_circle_im.shape}\")\n",
    "tensor_to_image(padded_circle_im)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MpRQdlDmmPz7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "f_circle_im = conv2d(padded_circle_im, sobel_ver)\n",
    "print(f\"shape -> {f_circle_im.shape}\")\n",
    "tensor_to_image(f_circle_im.abs())"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
