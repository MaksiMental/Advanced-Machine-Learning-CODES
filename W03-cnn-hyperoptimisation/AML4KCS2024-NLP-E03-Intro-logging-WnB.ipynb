{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: Logging using Weights & Biases\n",
    "\n",
    "ITU KSADMAL1KU-NLP - Advanced Machine Learning for NLP in KCS 2024\n",
    "\n",
    "by Bertram HÃ¸jer, Stefan Heinrich, Christian H. Rasmussen, & material by Kevin Murphy.\n",
    "\n",
    "All info and static material: https://learnit.itu.dk/course/view.php?id=3024579\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "In this notebook we reuse some code for training a simple model on MNIST from week 2 for a live coding session. \n",
    "We first simply log the training loss by printing the values, and then add additional weights&biases logging metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimpleNamespace(\n",
    "    learning_rate=0.01,\n",
    "    momentum=0.9,\n",
    "    epochs=5,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Create a dataloader for Pytorch training\n",
    "# download and load training dataset\n",
    "trainset = torchvision.datasets.MNIST(root='../data', train=True,\n",
    "                                      download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=config.batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "# download and load testing dataset\n",
    "testset = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                     download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False)\n",
    "\n",
    "img_size = trainloader.dataset.data.shape[1]\n",
    "class_out = trainloader.dataset.targets.unique().size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the model class\n",
    "class Model(nn.Module):\n",
    "\n",
    "  def __init__(self, img_size, fc1_out, fc2_out, class_out):\n",
    "      super(Model, self).__init__()\n",
    "\n",
    "      self.fc1 = nn.Linear(in_features=img_size*img_size, out_features=fc1_out)\n",
    "      self.fc2 = nn.Linear(in_features=fc1_out, out_features=fc2_out)\n",
    "      self.output_layer = nn.Linear(in_features=fc2_out, out_features=class_out)\n",
    "\n",
    "  def forward(self, img):\n",
    "\n",
    "    # we flatten the 2D image into one long array\n",
    "    img = img.flatten(start_dim=1)\n",
    "\n",
    "    x = self.fc1(img)\n",
    "    x = F.relu(x)\n",
    "    x = self.fc2(x)\n",
    "    x = F.relu(x)\n",
    "\n",
    "    x = self.output_layer(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimpleNamespace(\n",
    "    learning_rate=0.01,\n",
    "    momentum=0.9,\n",
    "    epochs=5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "img_size = trainloader.dataset.data.shape[1]\n",
    "class_out = trainloader.dataset.targets.unique().size()[0]\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cuda:mps\" if torch.cuda.is_available() and torch.cuda.get_device_properties(0).is_multi_gpu else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(img_size, 128, 128, class_out)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training specifics\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config.learning_rate, momentum=config.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def get_accuracy(logit, target, batch_size):\n",
    "    # compute accuracy\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()\n",
    "\n",
    "def train_model(model, config, trainloader, criterion, optimizer):\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        # Put the model in training mode\n",
    "        model = model.train()\n",
    "        \n",
    "        train_running_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "\n",
    "        for idx, (images, labels) in enumerate(trainloader):\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # loss and optimiser definitions!\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            loss.backward()\n",
    "        \n",
    "            # update model params\n",
    "            optimizer.step()\n",
    "        \n",
    "            train_running_loss += loss.detach().item()\n",
    "            train_acc += get_accuracy(logits, labels, config.batch_size)\n",
    "\n",
    "        print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \\\n",
    "            %(epoch, train_running_loss / idx, train_acc/idx))\n",
    "    \n",
    "    return model, train_running_loss, train_acc\n",
    "\n",
    "\n",
    "def eval_model(model, testloader):\n",
    "\n",
    "    model = model.eval()\n",
    "    test_acc = 0.0\n",
    "    for i, (images, labels) in enumerate(testloader, 0):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        test_acc += get_accuracy(outputs, labels, 1)\n",
    "\n",
    "    print(f\"Test Accuracy: {test_acc/i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the training loop\n",
    "model, _, _ = train_model(model, config, trainloader, criterion, optimizer)\n",
    "\n",
    "# After training your model, save the state_dict\n",
    "torch.save(model.state_dict(), \"model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training your model, save the state_dict\n",
    "torch.save(model.state_dict(), \"model_weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize W&B run\n",
    "run = wandb.init(project=\"aml-introduction\")\n",
    "wandb.config.update(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "# Create a dataloader for Pytorch training\n",
    "# download and load training dataset\n",
    "trainset = torchvision.datasets.MNIST(root='../data', train=True,\n",
    "                                      download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=config.batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "# download and load testing dataset\n",
    "testset = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                     download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wnb = Model(img_size, 128, 128, class_out)\n",
    "model_wnb = model_wnb.to(device)\n",
    "model_wnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training specifics\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_wnb.parameters(), lr=config.learning_rate, momentum=config.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_wnb(model, config, trainloader, criterion, optimizer):\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        # Put the model in training mode\n",
    "        model = model.train()\n",
    "        \n",
    "        train_running_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "\n",
    "        for idx, (images, labels) in enumerate(trainloader):\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # loss and optimiser definitions!\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            loss.backward()\n",
    "        \n",
    "            # update model params\n",
    "            optimizer.step()\n",
    "        \n",
    "            train_running_loss += loss.detach().item()\n",
    "            train_acc += get_accuracy(logits, labels, config.batch_size)\n",
    "\n",
    "        wandb.log({'Train Loss': train_running_loss / idx, 'Train Accuracy': train_acc/idx})\n",
    "    \n",
    "    return model, train_running_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# Train the W&B model\n",
    "model_wnb, _, _ = train_model_wnb(model_wnb, config, trainloader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and reloading trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model state as an artefact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training your model, save the state_dict\n",
    "torch.save(model_wnb.state_dict(), \"model_weights.pth\")\n",
    "\n",
    "# Log the model as an artifact\n",
    "artifact = wandb.Artifact('model', type='model')\n",
    "artifact.add_file(\"model_weights.pth\")\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "# Finish the run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model state into new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity: your entity, your username of the name of your team\n",
    "# project-name: your project name\n",
    "# model-version: the version of the model you want to download\n",
    "entity = ''\n",
    "project_name = ''\n",
    "model_version = ''\n",
    "\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact(f'{entity}/{project_name}/{model_version}', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the artifact contains a single file and it's the .pth file you want\n",
    "# If there are multiple files, you need to know the exact file name\n",
    "model_files = os.listdir(artifact_dir)\n",
    "model_file = [f for f in model_files if f.endswith('.pth')][0]\n",
    "model_path = os.path.join(artifact_dir, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinstatiate the model and load the weights\n",
    "model_wnb = Model(img_size, 128, 128, class_out)\n",
    "model_wnb.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(model, testloader)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
